{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbphTuVRG1tz"
      },
      "source": [
        "# Information retrieval challenge Task 2\n",
        "## Done by Ekaterina Timofeeva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oDuL420tGSH",
        "outputId": "ca0d4724-4bdc-4684-bad2-1d18021716cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train queries: 20\n",
            "Sample query ID: 79098180\n",
            "Gold docs for first query: ['1376881', '68722856', '7345574']\n",
            "Documents to rerank for first query: ['84117280', '86237859', '44417984', '43094034', '45901317', '42886784', '7345574', '43878837', '1354473', '86301854', '66025864', '86696791', '42365601', '86536566', '18158001', '70371603', '1376881', '81822743', '4082413', '4169775', '69328996', '68722856', '60044376', '84416764', '75998807', '42810307', '78288530', '103929967', '82465446', '87437516']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Utility function to load JSON\n",
        "def load_json(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Load data\n",
        "train_queries = load_json(\"train_queries.json\")\n",
        "gold_mappings = load_json(\"train_gold_mapping.json\")\n",
        "shuffled_ranking = load_json(\"shuffled_pre_ranking.json\")\n",
        "query_contents = load_json(\"queries_content_with_features.json\")\n",
        "document_contents = load_json(\"documents_content_with_features.json\")\n",
        "\n",
        "# Confirm data structure\n",
        "print(f\"Number of train queries: {len(train_queries)}\")\n",
        "print(f\"Sample query ID: {train_queries[0]}\")\n",
        "print(f\"Gold docs for first query: {gold_mappings[train_queries[0]]}\")\n",
        "print(f\"Documents to rerank for first query: {shuffled_ranking[train_queries[0]]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWTUtT7tGSY",
        "outputId": "fb467706-3153-43c6-edca-58fb7a44d9dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "900"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "len(document_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X0Y798qntGSa"
      },
      "outputs": [],
      "source": [
        "def list_to_dict_by_fan(data_list):\n",
        "    \"\"\"\n",
        "    Converts list of patent dicts into a dict keyed by patent ID (from FAN field).\n",
        "    \"\"\"\n",
        "    return {item[\"FAN\"]: item for item in data_list}\n",
        "\n",
        "# Apply conversion\n",
        "query_contents_dict = list_to_dict_by_fan(query_contents)\n",
        "document_contents_dict = list_to_dict_by_fan(document_contents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uTgJoqsF7u5"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv4B3Cm4F-1R"
      },
      "outputs": [],
      "source": [
        "# ! pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZcA6gXG4F-ya"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFWavX5oF-u-",
        "outputId": "df94f721-2179-425b-c5eb-01559333dca7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at intfloat/e5-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "model_name = \"intfloat/e5-large-v2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA-vesBtF-rW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reRE9-_9F-c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZDTUx_fEqHi"
      },
      "source": [
        "# Title + abstract\n",
        "\n",
        "0.211 on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNoLpHmjtGSd"
      },
      "outputs": [],
      "source": [
        "def extract_text_pairs_ta(query_ids, shuffled_ranking, query_contents, document_contents):\n",
        "    \"\"\"\n",
        "    Returns query-doc text pairs using Content['title'] + Content['pa01'] as 'TA' (Title + Abstract).\n",
        "    \"\"\"\n",
        "    data_pairs = {}\n",
        "\n",
        "    for qid in query_ids:\n",
        "        query_info = query_contents.get(qid, {}).get(\"Content\", {})\n",
        "        query_title = query_info.get(\"title\", \"\")\n",
        "        query_abstract = query_info.get(\"pa01\", \"\")\n",
        "        query_text = f\"{query_title}. {query_abstract}\"\n",
        "\n",
        "        doc_ids = shuffled_ranking[qid]\n",
        "        doc_tuples = []\n",
        "\n",
        "        for doc_id in doc_ids:\n",
        "            doc_info = document_contents.get(doc_id, {}).get(\"Content\", {})\n",
        "            doc_title = doc_info.get(\"title\", \"\")\n",
        "            doc_abstract = doc_info.get(\"pa01\", \"\")\n",
        "            doc_text = f\"{doc_title}. {doc_abstract}\"\n",
        "\n",
        "            doc_tuples.append((doc_id, query_text, doc_text))\n",
        "\n",
        "        data_pairs[qid] = doc_tuples\n",
        "\n",
        "    return data_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH_A3a5NtGSh",
        "outputId": "438140ad-b51f-4b53-c705-a107c89f649c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Text Sample:\n",
            " Universal dispenser monitor. A retrofit dispenser monitor is disclosed. The dispenser monitor has a connector allowing it to be connected directly to one of a number of dispensers. The dispenser monitor also comprises a sensor configured to detect the dispensing action of the attached dispenser by l\n",
            "First Doc Text Sample:\n",
            " Dispenser tool, robot system with dispenser tool and method for dispensing viscous material onto wind turbine blade surface. A dispenser tool is provided with multiple cartridges for dispensing viscous material onto the surface of a wind turbine blade . The dispenser tool is advantageously part of a\n"
          ]
        }
      ],
      "source": [
        "ta_pairs = extract_text_pairs_ta(\n",
        "    query_ids=train_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n",
        "\n",
        "sample_qid = train_queries[0]\n",
        "print(\"Query Text Sample:\\n\", ta_pairs[sample_qid][0][1][:300])\n",
        "print(\"First Doc Text Sample:\\n\", ta_pairs[sample_qid][0][2][:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHTu0ApCtGSp"
      },
      "outputs": [],
      "source": [
        "def score_query_doc_pairs(model, tokenizer, data_pairs, max_length=512, batch_size=8):\n",
        "    reranked_results = {}\n",
        "\n",
        "    for query_id, doc_pairs in tqdm(data_pairs.items(), desc=\"Scoring Queries\"):\n",
        "        scores = []\n",
        "        texts = [(query, doc) for (_, query, doc) in doc_pairs]\n",
        "        doc_ids = [doc_id for (doc_id, _, _) in doc_pairs]\n",
        "\n",
        "        # Batch processing\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            inputs = tokenizer(\n",
        "                [f\"{q} [SEP] {d}\" for q, d in batch],\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits.squeeze(-1)\n",
        "                batch_scores = logits.cpu().numpy().tolist()\n",
        "                scores.extend(batch_scores)\n",
        "\n",
        "        # Sort doc_ids by score (descending)\n",
        "        doc_score_pairs = sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)\n",
        "        reranked_results[query_id] = [doc_id for doc_id, _ in doc_score_pairs]\n",
        "\n",
        "    return reranked_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwaPv-7T3hRY",
        "outputId": "a7374995-7551-4aa9-a911-bf0d44bcffd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:49<00:00,  2.46s/it]\n"
          ]
        }
      ],
      "source": [
        "predictions_ta = score_query_doc_pairs(model, tokenizer, ta_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixjCSNjdwqTd"
      },
      "outputs": [],
      "source": [
        "def compute_map_and_recall(predictions, gold_mapping, k_values=[3, 5, 10, 20]):\n",
        "    results = {\n",
        "        \"MAP\": 0.0,\n",
        "        \"Recall@k\": {k: 0.0 for k in k_values},\n",
        "        \"Mean Rank\": 0.0,\n",
        "        \"Mean Inverse Rank\": 0.0\n",
        "    }\n",
        "\n",
        "    total_queries = 0\n",
        "    map_sum = 0.0\n",
        "    mean_rank_sum = 0.0\n",
        "    mean_inv_rank_sum = 0.0\n",
        "    recall_hits = {k: 0 for k in k_values}\n",
        "\n",
        "    for qid, ranked_docs in predictions.items():\n",
        "        if qid not in gold_mapping:\n",
        "            continue\n",
        "\n",
        "        gold_docs = set(gold_mapping[qid])\n",
        "        if not gold_docs:\n",
        "            continue\n",
        "\n",
        "        total_queries += 1\n",
        "        ap_sum = 0.0\n",
        "        hit_count = 0\n",
        "        first_hit_rank = None\n",
        "\n",
        "        for rank, doc_id in enumerate(ranked_docs, 1):\n",
        "            if doc_id in gold_docs:\n",
        "                hit_count += 1\n",
        "                ap_sum += hit_count / rank\n",
        "                if first_hit_rank is None:\n",
        "                    first_hit_rank = rank\n",
        "\n",
        "        # average precision\n",
        "        map_sum += ap_sum / len(gold_docs)\n",
        "\n",
        "        if first_hit_rank:\n",
        "            mean_rank_sum += first_hit_rank\n",
        "            mean_inv_rank_sum += 1 / first_hit_rank\n",
        "\n",
        "        # Recall@k logic\n",
        "        for k in k_values:\n",
        "            top_k = set(ranked_docs[:k])\n",
        "            if gold_docs & top_k:\n",
        "                recall_hits[k] += 1\n",
        "\n",
        "    if total_queries == 0:\n",
        "        return results\n",
        "\n",
        "    results[\"MAP\"] = map_sum / total_queries\n",
        "    results[\"Mean Rank\"] = mean_rank_sum / total_queries\n",
        "    results[\"Mean Inverse Rank\"] = mean_inv_rank_sum / total_queries\n",
        "\n",
        "    for k in k_values:\n",
        "        results[\"Recall@k\"][k] = recall_hits[k] / total_queries\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB9YXIXz3Z-_",
        "outputId": "db4eda9a-8c5d-47ec-db98-5ecad434f338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Evaluation Results on Training Data:\n",
            "MAP: 0.1876\n",
            "Recall@k@3: 0.3000\n",
            "Recall@k@5: 0.3500\n",
            "Recall@k@10: 0.7000\n",
            "Recall@k@20: 0.9500\n",
            "Mean Rank: 8.1000\n",
            "Mean Inverse Rank: 0.2380\n"
          ]
        }
      ],
      "source": [
        "eval_results = compute_map_and_recall(\n",
        "    predictions=predictions_ta,\n",
        "    gold_mapping=gold_mappings,  # from train_gold_mapping.json\n",
        "    k_values=[3, 5, 10, 20]\n",
        ")\n",
        "\n",
        "# Print metrics\n",
        "print(\"\\nðŸ” Evaluation Results on Training Data:\")\n",
        "for metric, value in eval_results.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38wbUyskFGZZ"
      },
      "source": [
        "# TA + claim 1\n",
        "\n",
        "0.242 on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-YH4Dm_-qRx"
      },
      "outputs": [],
      "source": [
        "def extract_text_pairs_tac1(query_ids, shuffled_ranking, query_contents, document_contents):\n",
        "    \"\"\"\n",
        "    Returns query-doc text pairs using:\n",
        "    Title + Abstract + First Claim (tac1)\n",
        "    \"\"\"\n",
        "    def get_first_claim(content_dict):\n",
        "        # Claims are labeled like 'c-en-0001', 'c-en-0002', etc.\n",
        "        for key in sorted(content_dict.keys()):\n",
        "            if key.startswith(\"c-en-\"):\n",
        "                return content_dict[key]\n",
        "        return \"\"\n",
        "\n",
        "    data_pairs = {}\n",
        "\n",
        "    for qid in query_ids:\n",
        "        query_info = query_contents.get(qid, {}).get(\"Content\", {})\n",
        "        query_title = query_info.get(\"title\", \"\")\n",
        "        query_abstract = query_info.get(\"pa01\", \"\")\n",
        "        query_first_claim = get_first_claim(query_info)\n",
        "        query_text = f\"{query_title}. {query_abstract}. {query_first_claim}\"\n",
        "\n",
        "        doc_ids = shuffled_ranking[qid]\n",
        "        doc_tuples = []\n",
        "\n",
        "        for doc_id in doc_ids:\n",
        "            doc_info = document_contents.get(doc_id, {}).get(\"Content\", {})\n",
        "            doc_title = doc_info.get(\"title\", \"\")\n",
        "            doc_abstract = doc_info.get(\"pa01\", \"\")\n",
        "            doc_first_claim = get_first_claim(doc_info)\n",
        "            doc_text = f\"{doc_title}. {doc_abstract}. {doc_first_claim}\"\n",
        "\n",
        "            doc_tuples.append((doc_id, query_text, doc_text))\n",
        "\n",
        "        data_pairs[qid] = doc_tuples\n",
        "\n",
        "    return data_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHIv6YE-w9k"
      },
      "outputs": [],
      "source": [
        "tac1_pairs = extract_text_pairs_tac1(\n",
        "    query_ids=train_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CID-Knes-6rL",
        "outputId": "e9c54267-28dc-4d4b-8359-51baa4057f18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:03<00:00,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.2065\n",
            "Recall@k@3: 0.3000\n",
            "Recall@k@5: 0.6000\n",
            "Recall@k@10: 0.8000\n",
            "Recall@k@20: 0.9500\n",
            "Mean Rank: 6.9000\n",
            "Mean Inverse Rank: 0.2965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictions_tac1 = score_query_doc_pairs(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=tac1_pairs,\n",
        "    batch_size=4\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "eval_tac1 = compute_map_and_recall(predictions_tac1, gold_mappings)\n",
        "\n",
        "# Display metrics\n",
        "for metric, value in eval_tac1.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT9kwNaWFOym"
      },
      "source": [
        "# TA + all claims\n",
        "\n",
        "0.203 on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmanGqiVCbjs"
      },
      "outputs": [],
      "source": [
        "def extract_text_pairs_all_claims(query_ids, shuffled_ranking, query_contents, document_contents):\n",
        "    def get_all_claims(content_dict):\n",
        "        return \" \".join(\n",
        "            content_dict[k] for k in sorted(content_dict) if k.startswith(\"c-en-\")\n",
        "        )\n",
        "\n",
        "    data_pairs = {}\n",
        "\n",
        "    for qid in query_ids:\n",
        "        query_info = query_contents.get(qid, {}).get(\"Content\", {})\n",
        "        query_title = query_info.get(\"title\", \"\")\n",
        "        query_abstract = query_info.get(\"pa01\", \"\")\n",
        "        query_claims = get_all_claims(query_info)\n",
        "        query_text = f\"{query_title}. {query_abstract}. {query_claims}\"\n",
        "\n",
        "        doc_ids = shuffled_ranking[qid]\n",
        "        doc_tuples = []\n",
        "\n",
        "        for doc_id in doc_ids:\n",
        "            doc_info = document_contents.get(doc_id, {}).get(\"Content\", {})\n",
        "            doc_title = doc_info.get(\"title\", \"\")\n",
        "            doc_abstract = doc_info.get(\"pa01\", \"\")\n",
        "            doc_claims = get_all_claims(doc_info)\n",
        "            doc_text = f\"{doc_title}. {doc_abstract}. {doc_claims}\"\n",
        "\n",
        "            doc_tuples.append((doc_id, query_text, doc_text))\n",
        "\n",
        "        data_pairs[qid] = doc_tuples\n",
        "\n",
        "    return data_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2mJPBhrCoTA"
      },
      "outputs": [],
      "source": [
        "claims_pairs = extract_text_pairs_all_claims(\n",
        "    query_ids=train_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YIdFia1C287",
        "outputId": "5a26e34f-7c41-499b-b6f8-5900d2871081"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:05<00:00,  3.29s/it]\n"
          ]
        }
      ],
      "source": [
        "predictions_claims = score_query_doc_pairs(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=claims_pairs,\n",
        "    batch_size=4  # reduce if needed for long inputs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o5muqlSC81z",
        "outputId": "f82956d7-0826-4620-e66c-71795f80791f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.2208\n",
            "Recall@k@3: 0.4000\n",
            "Recall@k@5: 0.6000\n",
            "Recall@k@10: 0.9000\n",
            "Recall@k@20: 0.9500\n",
            "Mean Rank: 6.3500\n",
            "Mean Inverse Rank: 0.2618\n"
          ]
        }
      ],
      "source": [
        "eval_claims = compute_map_and_recall(predictions_claims, gold_mappings)\n",
        "\n",
        "for metric, value in eval_claims.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_pU1NLnGsv6"
      },
      "source": [
        "# TAC1 + features\n",
        "\n",
        "Not submitted to codabench, since poor results on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe_rhuVJGvwX"
      },
      "outputs": [],
      "source": [
        "def extract_text_pairs_tac1f(query_ids, shuffled_ranking, query_contents, document_contents):\n",
        "    def get_first_claim(content_dict):\n",
        "        for key in sorted(content_dict.keys()):\n",
        "            if key.startswith(\"c-en-\"):\n",
        "                return content_dict[key]\n",
        "        return \"\"\n",
        "\n",
        "    data_pairs = {}\n",
        "\n",
        "    for qid in query_ids:\n",
        "        query_data = query_contents.get(qid, {})\n",
        "        content = query_data.get(\"Content\", {})\n",
        "        features = str(query_data.get(\"features\", \"\"))\n",
        "        query_text = f\"{content.get('title', '')}. {content.get('pa01', '')}. {get_first_claim(content)}. {features}\"\n",
        "\n",
        "        doc_ids = shuffled_ranking[qid]\n",
        "        doc_tuples = []\n",
        "\n",
        "        for doc_id in doc_ids:\n",
        "            doc_data = document_contents.get(doc_id, {})\n",
        "            content = doc_data.get(\"Content\", {})\n",
        "            features = str(doc_data.get(\"features\", \"\"))\n",
        "            doc_text = f\"{content.get('title', '')}. {content.get('pa01', '')}. {get_first_claim(content)}. {features}\"\n",
        "\n",
        "            doc_tuples.append((doc_id, query_text, doc_text))\n",
        "\n",
        "        data_pairs[qid] = doc_tuples\n",
        "\n",
        "    return data_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SinibNQLHMMs"
      },
      "outputs": [],
      "source": [
        "tac1f_pairs = extract_text_pairs_tac1f(\n",
        "    query_ids=train_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTfokuVaHSQA",
        "outputId": "cbb11580-15f3-427c-d5bc-e42268159718"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:00<00:00,  3.03s/it]\n"
          ]
        }
      ],
      "source": [
        "predictions_tac1f = score_query_doc_pairs(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=tac1f_pairs,\n",
        "    batch_size=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V58joiTiHVCD",
        "outputId": "ebb2cda9-c05e-4501-91e1-5670189eee86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.1819\n",
            "Recall@k@3: 0.2500\n",
            "Recall@k@5: 0.5500\n",
            "Recall@k@10: 0.8500\n",
            "Recall@k@20: 0.9500\n",
            "Mean Rank: 7.6000\n",
            "Mean Inverse Rank: 0.2079\n"
          ]
        }
      ],
      "source": [
        "eval_tac1f = compute_map_and_recall(predictions_tac1f, gold_mappings)\n",
        "\n",
        "for metric, value in eval_tac1f.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xe2fV5MJtMT"
      },
      "source": [
        "# Features\n",
        "\n",
        "0.202 on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6tVg1lRJvrU"
      },
      "outputs": [],
      "source": [
        "def extract_text_pairs_features_only(query_ids, shuffled_ranking, query_contents, document_contents):\n",
        "    data_pairs = {}\n",
        "\n",
        "    for qid in query_ids:\n",
        "        query_text = str(query_contents.get(qid, {}).get(\"features\", \"\"))\n",
        "\n",
        "        doc_ids = shuffled_ranking[qid]\n",
        "        doc_tuples = []\n",
        "\n",
        "        for doc_id in doc_ids:\n",
        "            doc_text = str(document_contents.get(doc_id, {}).get(\"features\", \"\"))\n",
        "            doc_tuples.append((doc_id, query_text, doc_text))\n",
        "\n",
        "        data_pairs[qid] = doc_tuples\n",
        "\n",
        "    return data_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Ucs47XJ0Kk"
      },
      "outputs": [],
      "source": [
        "features_pairs = extract_text_pairs_features_only(\n",
        "    query_ids=train_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_XKhXuLJ2Wk",
        "outputId": "acb69e2f-9131-4f11-8f52-b70d5484f5fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.12it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_features = score_query_doc_pairs(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=features_pairs,\n",
        "    batch_size=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuHUp0_bJ4tP",
        "outputId": "41ab4af8-3eea-4cb0-8b57-d65f71ff1ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.2140\n",
            "Recall@k@3: 0.4000\n",
            "Recall@k@5: 0.5500\n",
            "Recall@k@10: 0.9000\n",
            "Recall@k@20: 0.9000\n",
            "Mean Rank: 7.2000\n",
            "Mean Inverse Rank: 0.2984\n"
          ]
        }
      ],
      "source": [
        "eval_features = compute_map_and_recall(predictions_features, gold_mappings)\n",
        "\n",
        "for metric, value in eval_features.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTlQL-4034w-"
      },
      "source": [
        "# Encoder fine-tuning\n",
        "\n",
        "Results on test set:\n",
        "\n",
        "distilroberta (fine-tuned)\t0.227\n",
        "\n",
        "e5-large-v2 (fine-tuned)\t0.200\n",
        "\n",
        "MiniLM v2 (fine-tuned)\t0.225"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs_U5nU033Cj"
      },
      "outputs": [],
      "source": [
        "def prepare_training_data_tac1(\n",
        "    train_queries,\n",
        "    gold_mappings,\n",
        "    shuffled_ranking,\n",
        "    query_contents,\n",
        "    document_contents,\n",
        "    max_negatives_per_query=10\n",
        "):\n",
        "    def get_first_claim(content_dict):\n",
        "        for key in sorted(content_dict):\n",
        "            if key.startswith(\"c-en-\"):\n",
        "                return content_dict[key]\n",
        "        return \"\"\n",
        "\n",
        "    training_data = []\n",
        "\n",
        "    for qid in train_queries:\n",
        "        query_data = query_contents.get(qid, {})\n",
        "        query_content = query_data.get(\"Content\", {})\n",
        "        query_text = f\"{query_content.get('title', '')}. {query_content.get('pa01', '')}. {get_first_claim(query_content)}\"\n",
        "\n",
        "        gold_docs = set(gold_mappings.get(qid, []))\n",
        "        candidates = shuffled_ranking.get(qid, [])\n",
        "\n",
        "        # Add positives\n",
        "        for doc_id in candidates:\n",
        "            if doc_id in gold_docs:\n",
        "                doc_data = document_contents.get(doc_id, {})\n",
        "                doc_content = doc_data.get(\"Content\", {})\n",
        "                doc_text = f\"{doc_content.get('title', '')}. {doc_content.get('pa01', '')}. {get_first_claim(doc_content)}\"\n",
        "                training_data.append((query_text, doc_text, 1))\n",
        "\n",
        "        # Add negatives (not in gold)\n",
        "        negatives_added = 0\n",
        "        for doc_id in candidates:\n",
        "            if doc_id not in gold_docs:\n",
        "                doc_data = document_contents.get(doc_id, {})\n",
        "                doc_content = doc_data.get(\"Content\", {})\n",
        "                doc_text = f\"{doc_content.get('title', '')}. {doc_content.get('pa01', '')}. {get_first_claim(doc_content)}\"\n",
        "                training_data.append((query_text, doc_text, 0))\n",
        "                negatives_added += 1\n",
        "                if negatives_added >= max_negatives_per_query:\n",
        "                    break\n",
        "\n",
        "    print(f\"Prepared {len(training_data)} training pairs.\")\n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRm6uLR64KLd",
        "outputId": "b6672c61-ccb0-4aab-c5f9-ef923e901e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 269 training pairs.\n"
          ]
        }
      ],
      "source": [
        "train_data = prepare_training_data_tac1(\n",
        "    train_queries=train_queries,\n",
        "    gold_mappings=gold_mappings,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict,\n",
        "    max_negatives_per_query=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhKN5OXV4MuR",
        "outputId": "e50bf703-a14c-4c28-a227-1c0d66e7a8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Label: 1]\n",
            "Query: Universal dispenser monitor. A retrofit dispenser monitor is disclosed. The dispenser monitor has a connector allowing it to be connected directly to one of a number of dispensers. The dispenser monit ...\n",
            "Doc:   Hygiene compliance module. A hygiene compliance module is configured to be retrofit with a compatible dispenser to enable hygiene compliance monitoring functions. The hygiene compliance module is conf ...\n",
            "\n",
            "[Label: 1]\n",
            "Query: Universal dispenser monitor. A retrofit dispenser monitor is disclosed. The dispenser monitor has a connector allowing it to be connected directly to one of a number of dispensers. The dispenser monit ...\n",
            "Doc:   System for managing multiple dispensing units and method of operation. A system for managing multiple dispensing units by communicating information through a communications network is provided. The sy ...\n"
          ]
        }
      ],
      "source": [
        "# Print a sample\n",
        "for i in range(2):\n",
        "    print(f\"\\n[Label: {train_data[i][2]}]\")\n",
        "    print(\"Query:\", train_data[i][0][:200], \"...\")\n",
        "    print(\"Doc:  \", train_data[i][1][:200], \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTo5bTbD4icB"
      },
      "outputs": [],
      "source": [
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPRFIIkR40eJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=1  # binary relevance score (0 or 1)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9zMs0L945Ua"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PatentPairDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query_text, doc_text, label = self.data[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            query_text,\n",
        "            doc_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcpsZrSn47j5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = PatentPairDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNhWkBNu49ze",
        "outputId": "a240c378-eeb8-4cd2-c80e-3e7fb2f10045"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 384)\n",
              "      (token_type_embeddings): Embedding(2, 384)\n",
              "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=384, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt7uSEm75HyR"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.5e-5)\n",
        "loss_fn = BCEWithLogitsLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnWN9d6r5img"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, optimizer, loss_fn, device, epochs=3):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "        for batch in progress:\n",
        "            # Move to device\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.squeeze(-1)\n",
        "\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "            # Backward + optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"âœ… Epoch {epoch+1} complete. Avg loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CecV73UI5j4v",
        "outputId": "62ba644e-9b5b-4f5f-f5fa-25838117a480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00, 10.48it/s, loss=0.221]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 1 complete. Avg loss: 0.7825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00, 10.86it/s, loss=0.484]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 2 complete. Avg loss: 0.6029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00, 10.55it/s, loss=0.241]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 3 complete. Avg loss: 0.5647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, optimizer, loss_fn, device, epochs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSnuLrSr5yev"
      },
      "outputs": [],
      "source": [
        "def rerank_with_model(model, tokenizer, data_pairs, max_length=512, batch_size=4):\n",
        "    model.eval()\n",
        "    reranked_results = {}\n",
        "\n",
        "    for query_id, doc_pairs in tqdm(data_pairs.items(), desc=\"Reranking\"):\n",
        "        scores = []\n",
        "        texts = [(query, doc) for (_, query, doc) in doc_pairs]\n",
        "        doc_ids = [doc_id for (doc_id, _, _) in doc_pairs]\n",
        "\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            inputs = tokenizer(\n",
        "                [f\"{q} [SEP] {d}\" for q, d in batch],\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits.squeeze(-1)\n",
        "                scores_batch = logits.cpu().numpy().tolist()\n",
        "                scores.extend(scores_batch)\n",
        "\n",
        "        # Sort docs by score\n",
        "        doc_score_pairs = sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)\n",
        "        reranked_results[query_id] = [doc_id for doc_id, _ in doc_score_pairs]\n",
        "\n",
        "    return reranked_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZecq7df50tw",
        "outputId": "e7f158d2-08e0-4765-b912-825db279505f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.21it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_ft_train = rerank_with_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=tac1_pairs,\n",
        "    batch_size=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eArIgXNT5_Jc",
        "outputId": "31a40081-da5a-40c5-a88e-bd25330a6ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: 0.2500\n",
            "Recall@k@3: 0.5000\n",
            "Recall@k@5: 0.6500\n",
            "Recall@k@10: 0.9000\n",
            "Recall@k@20: 1.0000\n",
            "Mean Rank: 4.9500\n",
            "Mean Inverse Rank: 0.3207\n"
          ]
        }
      ],
      "source": [
        "eval_ft = compute_map_and_recall(predictions_ft_train, gold_mappings)\n",
        "\n",
        "for metric, value in eval_ft.items():\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            print(f\"{metric}@{k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj-GSXbWFXbc"
      },
      "source": [
        "# GENERATE TEST PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51lsHS64Dp3Z"
      },
      "outputs": [],
      "source": [
        "# 1. Load test query IDs\n",
        "test_queries = load_json(\"test_queries.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF-_u-7q6VHF",
        "outputId": "81199ec9-d9f9-4919-bfb9-418d518f9071"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… predictions2.json is ready for test submission.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tac1_pairs_test = extract_text_pairs_tac1(\n",
        "    query_ids=test_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n",
        "predictions_ft_test = rerank_with_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=tac1_pairs_test,\n",
        "    batch_size=4\n",
        ")\n",
        "with open(\"prediction2.json\", \"w\") as f:\n",
        "    json.dump(predictions_ft_test, f, indent=2)\n",
        "\n",
        "print(\"âœ… predictions2.json is ready for test submission.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loHLQH5ZKVYi",
        "outputId": "4298c663-affa-451b-acfd-dadfe8190c9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Submission file ready for test upload (features only)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "features_pairs_test = extract_text_pairs_features_only(\n",
        "    query_ids=test_queries,\n",
        "    shuffled_ranking=shuffled_ranking,\n",
        "    query_contents=query_contents_dict,\n",
        "    document_contents=document_contents_dict\n",
        ")\n",
        "\n",
        "predictions_test_features = score_query_doc_pairs(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_pairs=features_pairs_test,\n",
        "    batch_size=4\n",
        ")\n",
        "\n",
        "with open(\"prediction2.json\", \"w\") as f:\n",
        "    json.dump(predictions_test_features, f, indent=2)\n",
        "\n",
        "print(\"âœ… Submission file ready for test upload (features only)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il-lj5oKDiq0",
        "outputId": "5a97ce17-c581-4c1d-b108-6cf21d26d0d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Test prediction saved. Ready to upload.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# claims_pairs_test = extract_text_pairs_all_claims(\n",
        "#     query_ids=test_queries,\n",
        "#     shuffled_ranking=shuffled_ranking,\n",
        "#     query_contents=query_contents_dict,\n",
        "#     document_contents=document_contents_dict\n",
        "# )\n",
        "\n",
        "# predictions_test_claims = score_query_doc_pairs(\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_pairs=claims_pairs_test,\n",
        "#     batch_size=4\n",
        "# )\n",
        "\n",
        "# with open(\"prediction2.json\", \"w\") as f:\n",
        "#     json.dump(predictions_test_claims, f, indent=2)\n",
        "\n",
        "# print(\"âœ… Test prediction saved. Ready to upload.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDCdFRISvcYJ",
        "outputId": "30528ee5-be16-443c-ec04-ddb4e267f305"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved test predictions to prediction2.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# # ta_pairs_test = extract_text_pairs_ta(\n",
        "# #     query_ids=test_queries,\n",
        "# #     shuffled_ranking=shuffled_ranking,\n",
        "# #     query_contents=query_contents_dict,\n",
        "# #     document_contents=document_contents_dict\n",
        "# # )\n",
        "# tac1_pairs_test = extract_text_pairs_tac1(\n",
        "#     query_ids=test_queries,\n",
        "#     shuffled_ranking=shuffled_ranking,\n",
        "#     query_contents=query_contents_dict,\n",
        "#     document_contents=document_contents_dict\n",
        "# )\n",
        "# # 3. Run scoring on test pairs using your model\n",
        "# predictions_test = score_query_doc_pairs(\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_pairs=tac1_pairs_test,\n",
        "#     max_length=512,\n",
        "#     batch_size=8\n",
        "# )\n",
        "\n",
        "# # 4. Save predictions to JSON\n",
        "# with open(\"prediction2.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(predictions_test, f, indent=2)\n",
        "\n",
        "# print(\"âœ… Saved test predictions to prediction2.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smNkWKwbaiiH"
      },
      "source": [
        "## Done by Kseniia Pavlova"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Utility function to load JSON\n",
        "def load_json(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Load data\n",
        "train_queries = load_json(\"train_queries.json\")\n",
        "gold_mappings = load_json(\"train_gold_mapping.json\")\n",
        "shuffled_ranking = load_json(\"shuffled_pre_ranking.json\")\n",
        "query_contents = load_json(\"queries_content_with_features.json\")\n",
        "document_contents = load_json(\"documents_content_with_features.json\")\n",
        "\n",
        "# Convert to dict format\n",
        "def list_to_dict_by_fan(data_list):\n",
        "    return {item[\"FAN\"]: item for item in data_list}\n",
        "\n",
        "query_contents_dict = list_to_dict_by_fan(query_contents)\n",
        "document_contents_dict = list_to_dict_by_fan(document_contents)"
      ],
      "metadata": {
        "id": "HlKAqEzJcuMK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define all text extraction functions\n",
        "def extract_ta(content_dict):\n",
        "    \"\"\"Title + Abstract\"\"\"\n",
        "    content = content_dict.get(\"Content\", {})\n",
        "    return f\"{content.get('title', '')}. {content.get('pa01', '')}\"\n",
        "\n",
        "# Corrected text extraction functions\n",
        "def extract_tac1(content_dict):\n",
        "    \"\"\"Title + Abstract + Claim 1\"\"\"\n",
        "    content = content_dict.get(\"Content\", {})\n",
        "    first_claim = next((content[k] for k in sorted(content) if k.startswith(\"c-en-\")), \"\")\n",
        "    return f\"{content.get('title', '')}. {content.get('pa01', '')}. {first_claim}\"\n",
        "\n",
        "def extract_tac1f(content_dict):\n",
        "    \"\"\"Title + Abstract + Claim 1 + Features\"\"\"\n",
        "    content = content_dict.get(\"Content\", {})\n",
        "    features = content_dict.get(\"features\", \"\")\n",
        "    first_claim = next((content[k] for k in sorted(content) if k.startswith(\"c-en-\")), \"\")\n",
        "    return f\"{content.get('title', '')}. {content.get('pa01', '')}. {first_claim}. {features}\"\n",
        "\n",
        "def extract_all_claims(content_dict):\n",
        "    \"\"\"Title + Abstract + All Claims\"\"\"\n",
        "    content = content_dict.get(\"Content\", {})\n",
        "    claims = \" \".join(content[k] for k in sorted(content) if k.startswith(\"c-en-\"))\n",
        "    return f\"{content.get('title', '')}. {content.get('pa01', '')}. {claims}\"\n",
        "\n",
        "def extract_features_only(content_dict):\n",
        "    \"\"\"Features only\"\"\"\n",
        "    return str(content_dict.get(\"features\", \"\"))"
      ],
      "metadata": {
        "id": "m6McvJi1cunI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load bi-encoder model\n",
        "model_name = \"BAAI/bge-large-en-v1.5\"\n",
        "model = SentenceTransformer(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJj9dyFucw3g",
        "outputId": "0962910c-18b9-458a-e917-09733871bfac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all documents for each representation type\n",
        "def encode_corpus(docs_dict, text_extractor, batch_size=32):\n",
        "    doc_ids = list(docs_dict.keys())\n",
        "    texts = [text_extractor(docs_dict[doc_id]) for doc_id in doc_ids]\n",
        "    embeddings = model.encode(texts, batch_size=batch_size, show_progress_bar=True)\n",
        "    return {doc_id: emb for doc_id, emb in zip(doc_ids, embeddings)}\n",
        "\n",
        "print(\"Encoding documents for all representations...\")\n",
        "doc_embeddings_ta = encode_corpus(document_contents_dict, extract_ta)\n",
        "doc_embeddings_tac1 = encode_corpus(document_contents_dict, extract_tac1)\n",
        "doc_embeddings_tac1f = encode_corpus(document_contents_dict, extract_tac1f)\n",
        "doc_embeddings_all_claims = encode_corpus(document_contents_dict, extract_all_claims)\n",
        "doc_embeddings_features = encode_corpus(document_contents_dict, extract_features_only)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "2f805439dcde457296ca7b45823abbcd",
            "5f1a4118201842a39089e3637d81156e",
            "5a621d0449ce49bc8220944d8eddb228",
            "2c3b83e9e45e4cbca3540cad62195138",
            "9b94c57e3fd94fba91817764faeb1b98",
            "593ecc7c30a14af19f2191d4b8fc0390",
            "9be351be88634168900c10dcc0b818e3",
            "ecbd2256d3bb4ac4bff77361d06af675",
            "d9c9220cba2248e2bbdea32c33226b20",
            "d58e47e447b84c86aece5e74ec6cc6cd",
            "3446f7f9db7042e3a5cdb5b9edb177bd",
            "1894c4d5f05a4fde932f06c2b386a213",
            "3d4f8d1d39004dc1a17a7c7d6b0c4285",
            "13be0f874076458d878553637d26ed22",
            "2bfe19e92e164875a636b7e75ca88e75",
            "83d0b8971755412fbc2916236fe8c748",
            "91e7ef78ea25463d8a04f2dbc3534a16",
            "8eebcb0373ef4be59508284e1f908843",
            "0813ca2d96e34625854cb3150db78f44",
            "eb27edf825a04b9f82f803950f861c7b",
            "f7705ae862c04aadb12340ce2e99dceb",
            "8b0e4c9629d24a1a88c1f8e2d046a832",
            "f36241357cfb4e71830c67b3a6dc3cea",
            "2762b0401e8f46aea987504fb4622bc1",
            "f6afdaf8acd64b698197fa2e648150ee",
            "eddb16de9dd6477b981f21a924104037",
            "d79d8fe993e7479380c532e67553335e",
            "4315521d259c4501be6db90ff5b5aad9",
            "b9bb567f8df44db89dd2ffae6318676c",
            "0fab72471ef148b8954fae0058eda580",
            "27f0ee3a5dda44379004fb145582a6d7",
            "3fd149bff6f44a8796c93cc49a2eaa0f",
            "a48fe086795d4413866b46d8f107c220",
            "963c0a96dd534ce997649bf332438d44",
            "acde63c4177b48229bb8a2fc479f1642",
            "b9c237694adc49aea6db79ca4a98a9e2",
            "623060236bcd4e0ea9ee53885345dcc2",
            "1834d4421a80441daf4782da40720a4e",
            "43d59320f3a24e76bd9b69c3bf7417d5",
            "231e4dfab2f2466d928b73b1c9f36ed0",
            "a2ec38d86e8a4ec9ae6a36fb40e02780",
            "88d8dfaf29d54da992b6e6624ef48b18",
            "0910e1120e6f410bb0bfb67cb4487d33",
            "6dc2cc5f97c7415a9ab7b9079a37316f",
            "468e881ed4a5401b921f026bf50f9fc4",
            "1a1858b2f35a4310a9d1d49f8b4de813",
            "04b3db8f14cc45108d1abfbc58295c99",
            "98c2e6d76d174fa0b0bec6d0cfc21903",
            "67bf5f2164064a6ea8da1e6d9a74e3f4",
            "4e4e46f1876a46cca23ae3cf0fef08a4",
            "e2a8d831fc2b47ecad2f4d25952a843b",
            "306d6a50ff274c2b9290721b5d20777e",
            "984a37e6d9594941b3046dcd8424dce2",
            "4a1626754fa74f71ad06921690efced6",
            "535afa9acf334e398d03a4a237b434e5"
          ]
        },
        "id": "pgrig17ldd4-",
        "outputId": "c4789054-976f-44fd-d01c-220039545f7f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents for all representations...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f805439dcde457296ca7b45823abbcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1894c4d5f05a4fde932f06c2b386a213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f36241357cfb4e71830c67b3a6dc3cea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "963c0a96dd534ce997649bf332438d44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "468e881ed4a5401b921f026bf50f9fc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_queries(query_ids, shuffled_ranking, query_contents, doc_embeddings, text_extractor):\n",
        "    reranked_results = {}\n",
        "\n",
        "    for qid in tqdm(query_ids, desc=\"Reranking queries\"):\n",
        "        # Get query text and encode\n",
        "        query_text = text_extractor(query_contents.get(qid, {}))\n",
        "        query_embedding = model.encode(query_text)\n",
        "\n",
        "        # Get candidate docs and their embeddings\n",
        "        candidate_docs = shuffled_ranking[qid]\n",
        "        doc_embs = torch.stack([torch.tensor(doc_embeddings[doc_id]) for doc_id in candidate_docs])\n",
        "\n",
        "        # Compute similarities\n",
        "        query_emb_tensor = torch.tensor(query_embedding).to(device)\n",
        "        doc_embs = doc_embs.to(device)\n",
        "        scores = util.cos_sim(query_emb_tensor, doc_embs)[0]\n",
        "\n",
        "        # Sort by score\n",
        "        sorted_indices = torch.argsort(scores, descending=True)\n",
        "        reranked_results[qid] = [candidate_docs[i] for i in sorted_indices]\n",
        "\n",
        "    return reranked_results"
      ],
      "metadata": {
        "id": "VM1dJ0YWdgJG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def compute_map_and_recall(predictions, gold_mapping, k_values=[3, 5, 10, 20]):\n",
        "    results = {\n",
        "        \"MAP\": 0.0,\n",
        "        \"Recall@k\": {k: 0.0 for k in k_values},\n",
        "        \"Mean Rank\": 0.0,\n",
        "        \"Mean Inverse Rank\": 0.0\n",
        "    }\n",
        "\n",
        "    total_queries = 0\n",
        "    map_sum = 0.0\n",
        "    mean_rank_sum = 0.0\n",
        "    mean_inv_rank_sum = 0.0\n",
        "    recall_hits = {k: 0 for k in k_values}\n",
        "\n",
        "    for qid, ranked_docs in predictions.items():\n",
        "        if qid not in gold_mapping:\n",
        "            continue\n",
        "\n",
        "        gold_docs = set(gold_mapping[qid])\n",
        "        if not gold_docs:\n",
        "            continue\n",
        "\n",
        "        total_queries += 1\n",
        "        ap_sum = 0.0\n",
        "        hit_count = 0\n",
        "        first_hit_rank = None\n",
        "\n",
        "        for rank, doc_id in enumerate(ranked_docs, 1):\n",
        "            if doc_id in gold_docs:\n",
        "                hit_count += 1\n",
        "                ap_sum += hit_count / rank\n",
        "                if first_hit_rank is None:\n",
        "                    first_hit_rank = rank\n",
        "\n",
        "        map_sum += ap_sum / len(gold_docs)\n",
        "\n",
        "        if first_hit_rank:\n",
        "            mean_rank_sum += first_hit_rank\n",
        "            mean_inv_rank_sum += 1 / first_hit_rank\n",
        "\n",
        "        for k in k_values:\n",
        "            top_k = set(ranked_docs[:k])\n",
        "            if gold_docs & top_k:\n",
        "                recall_hits[k] += 1\n",
        "\n",
        "    if total_queries > 0:\n",
        "        results[\"MAP\"] = map_sum / total_queries\n",
        "        results[\"Mean Rank\"] = mean_rank_sum / total_queries\n",
        "        results[\"Mean Inverse Rank\"] = mean_inv_rank_sum / total_queries\n",
        "        for k in k_values:\n",
        "            results[\"Recall@k\"][k] = recall_hits[k] / total_queries\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_results(results, name):\n",
        "    print(f\"\\nðŸ” Evaluation Results ({name}):\")\n",
        "    for metric, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            for k, v in value.items():\n",
        "                print(f\"{metric}@{k}: {v:.4f}\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "3s23QO07dkUn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all representations\n",
        "print(\"Evaluating all representations...\")\n",
        "\n",
        "# 1. Title + Abstract (TA)\n",
        "predictions_ta = rerank_queries(train_queries, shuffled_ranking, query_contents_dict, doc_embeddings_ta, extract_ta)\n",
        "results_ta = compute_map_and_recall(predictions_ta, gold_mappings)\n",
        "print_results(results_ta, \"Title + Abstract\")\n",
        "\n",
        "# 2. Title + Abstract + Claim 1 (TAC1)\n",
        "predictions_tac1 = rerank_queries(train_queries, shuffled_ranking, query_contents_dict, doc_embeddings_tac1, extract_tac1)\n",
        "results_tac1 = compute_map_and_recall(predictions_tac1, gold_mappings)\n",
        "print_results(results_tac1, \"Title + Abstract + Claim 1\")\n",
        "\n",
        "# 3. Title + Abstract + Claim 1 + Features (TAC1F)\n",
        "predictions_tac1f = rerank_queries(train_queries, shuffled_ranking, query_contents_dict, doc_embeddings_tac1f, extract_tac1f)\n",
        "results_tac1f = compute_map_and_recall(predictions_tac1f, gold_mappings)\n",
        "print_results(results_tac1f, \"Title + Abstract + Claim 1 + Features\")\n",
        "\n",
        "# 4. All Claims\n",
        "predictions_all_claims = rerank_queries(train_queries, shuffled_ranking, query_contents_dict, doc_embeddings_all_claims, extract_all_claims)\n",
        "results_all_claims = compute_map_and_recall(predictions_all_claims, gold_mappings)\n",
        "print_results(results_all_claims, \"All Claims\")\n",
        "\n",
        "# 5. Features Only\n",
        "predictions_features = rerank_queries(train_queries, shuffled_ranking, query_contents_dict, doc_embeddings_features, extract_features_only)\n",
        "results_features = compute_map_and_recall(predictions_features, gold_mappings)\n",
        "print_results(results_features, \"Features Only\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEL1W3ZYdknm",
        "outputId": "d4945701-8fd6-4869-9a6b-3977a884c6c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating all representations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reranking queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Evaluation Results (Title + Abstract):\n",
            "MAP: 0.2199\n",
            "Recall@k@3: 0.3500\n",
            "Recall@k@5: 0.4500\n",
            "Recall@k@10: 0.7500\n",
            "Recall@k@20: 0.8500\n",
            "Mean Rank: 7.9500\n",
            "Mean Inverse Rank: 0.2749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reranking queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 10.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Evaluation Results (Title + Abstract + Claim 1):\n",
            "MAP: 0.2016\n",
            "Recall@k@3: 0.3000\n",
            "Recall@k@5: 0.5000\n",
            "Recall@k@10: 0.7500\n",
            "Recall@k@20: 0.9000\n",
            "Mean Rank: 8.0500\n",
            "Mean Inverse Rank: 0.2472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reranking queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 10.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Evaluation Results (Title + Abstract + Claim 1 + Features):\n",
            "MAP: 0.2023\n",
            "Recall@k@3: 0.3000\n",
            "Recall@k@5: 0.5000\n",
            "Recall@k@10: 0.7500\n",
            "Recall@k@20: 0.9000\n",
            "Mean Rank: 8.1000\n",
            "Mean Inverse Rank: 0.2470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reranking queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Evaluation Results (All Claims):\n",
            "MAP: 0.2023\n",
            "Recall@k@3: 0.3000\n",
            "Recall@k@5: 0.4000\n",
            "Recall@k@10: 0.7500\n",
            "Recall@k@20: 0.9000\n",
            "Mean Rank: 8.3500\n",
            "Mean Inverse Rank: 0.2557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reranking queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 49.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Evaluation Results (Features Only):\n",
            "MAP: 0.2127\n",
            "Recall@k@3: 0.4000\n",
            "Recall@k@5: 0.4000\n",
            "Recall@k@10: 0.7000\n",
            "Recall@k@20: 0.9500\n",
            "Mean Rank: 8.2000\n",
            "Mean Inverse Rank: 0.2920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other vertion of TAC1+Features\n",
        "\n",
        "CONFIG = {\n",
        "    \"data_dir\": \".\",\n",
        "    \"output_file\": \"prediction2.json\",\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"bi_encoder\": \"BAAI/bge-large-en-v1.5\",\n",
        "    \"cross_encoder\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    \"max_length\": 512,\n",
        "    \"batch_size\": 32\n",
        "}\n",
        "\n",
        "class PatentReranker:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.data = self._load_data()\n",
        "        self.feature_stats = self._get_feature_stats()\n",
        "        self._init_models()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Load all data files\"\"\"\n",
        "        files = {\n",
        "            \"test_queries\": \"test_queries.json\",\n",
        "            \"queries_content\": \"queries_content_with_features.json\",\n",
        "            \"docs_content\": \"documents_content_with_features.json\",\n",
        "            \"pre_ranking\": \"shuffled_pre_ranking.json\"\n",
        "        }\n",
        "\n",
        "        data = {}\n",
        "        for key, filename in files.items():\n",
        "            with open(f\"{self.config['data_dir']}/{filename}\", \"r\") as f:\n",
        "                data[key] = json.load(f)\n",
        "\n",
        "        # Convert content lists to dictionaries\n",
        "        for content_type in [\"queries_content\", \"docs_content\"]:\n",
        "            if isinstance(data[content_type], list):\n",
        "                data[content_type] = {item[\"FAN\"]: item for item in data[content_type]}\n",
        "\n",
        "        return data\n",
        "\n",
        "    def _get_feature_stats(self):\n",
        "        \"\"\"Calculate feature frequencies for weighting\"\"\"\n",
        "        feature_counts = defaultdict(int)\n",
        "        for doc in self.data[\"docs_content\"].values():\n",
        "            for feature in doc[\"Content\"][\"features\"]:\n",
        "                feature_counts[feature] += 1\n",
        "        return feature_counts\n",
        "\n",
        "    def _init_models(self):\n",
        "        \"\"\"Initialize the models\"\"\"\n",
        "        self.bi_encoder = SentenceTransformer(\n",
        "            self.config[\"bi_encoder\"],\n",
        "            device=self.config[\"device\"]\n",
        "        )\n",
        "        self.bi_encoder.max_seq_length = self.config[\"max_length\"]\n",
        "\n",
        "        self.cross_encoder = CrossEncoder(\n",
        "            self.config[\"cross_encoder\"],\n",
        "            device=self.config[\"device\"]\n",
        "        )\n",
        "\n",
        "    def _get_text(self, patent_data):\n",
        "        \"\"\"Enhanced text extraction\"\"\"\n",
        "        content = patent_data[\"Content\"]\n",
        "        parts = [\n",
        "            content.get(\"title\", \"\"),\n",
        "            content.get(\"pa01\", \"\"),  # First paragraph as abstract\n",
        "            *[v for k,v in content.items() if k.startswith(\"c-en\")],  # English claims\n",
        "            *[v for k,v in content.items() if k.startswith(\"p\") and len(k.split('-')) == 2]  # Main paragraphs\n",
        "        ]\n",
        "        return \" \".join(parts).strip()\n",
        "\n",
        "    def _get_feature_score(self, query_features, doc_features):\n",
        "        \"\"\"Weighted feature overlap scoring\"\"\"\n",
        "        if not self.feature_stats:\n",
        "            return len(set(query_features) & set(doc_features))\n",
        "\n",
        "        total_docs = len(self.feature_stats)\n",
        "        weights = {f: np.log(total_docs/(1+self.feature_stats[f])) for f in query_features}\n",
        "        return sum(weights.get(f, 0) for f in doc_features if f in weights)\n",
        "\n",
        "    def _rerank_documents(self, query_id, doc_ids):\n",
        "        \"\"\"Core re-ranking logic\"\"\"\n",
        "        # Get query data\n",
        "        query_content = self.data[\"queries_content\"][query_id]\n",
        "        query_text = self._get_text(query_content)\n",
        "        query_features = query_content[\"Content\"][\"features\"]\n",
        "\n",
        "        # Get document data\n",
        "        doc_contents = [self.data[\"docs_content\"][did] for did in doc_ids]\n",
        "        doc_texts = [self._get_text(doc) for doc in doc_contents]\n",
        "        doc_features = [doc[\"Content\"][\"features\"] for doc in doc_contents]\n",
        "\n",
        "        # Stage 1: Bi-encoder\n",
        "        query_embed = self.bi_encoder.encode([query_text])[0]\n",
        "        doc_embeds = self.bi_encoder.encode(doc_texts, batch_size=self.config[\"batch_size\"])\n",
        "        bi_scores = util.cos_sim(query_embed, doc_embeds)[0].cpu().numpy()\n",
        "\n",
        "        # Stage 2: Cross-encoder on top candidates\n",
        "        top_k = min(15, len(doc_ids))\n",
        "        top_indices = np.argsort(bi_scores)[-top_k:][::-1]\n",
        "\n",
        "        cross_inputs = [(query_text, doc_texts[i]) for i in top_indices]\n",
        "        cross_scores = self.cross_encoder.predict(cross_inputs)\n",
        "\n",
        "        # Feature scores\n",
        "        feature_scores = np.array([\n",
        "            self._get_feature_score(query_features, features)\n",
        "            for features in doc_features\n",
        "        ])\n",
        "\n",
        "        # Normalize and combine scores\n",
        "        bi_scores = (bi_scores - bi_scores.min()) / (bi_scores.max() - bi_scores.min() + 1e-8)\n",
        "        feature_scores = (feature_scores - feature_scores.min()) / (feature_scores.max() - feature_scores.min() + 1e-8)\n",
        "\n",
        "        # Combined scoring\n",
        "        final_scores = 0.6*bi_scores + 0.3*feature_scores\n",
        "        for idx, score in zip(top_indices, cross_scores):\n",
        "            final_scores[idx] = 0.4*bi_scores[idx] + 0.4*score + 0.2*feature_scores[idx]\n",
        "\n",
        "        return [doc_ids[i] for i in np.argsort(final_scores)[::-1]]\n",
        "\n",
        "    def generate_submission(self):\n",
        "        \"\"\"Generate the submission file\"\"\"\n",
        "        predictions = {}\n",
        "\n",
        "        for query_id in tqdm(self.data[\"test_queries\"], desc=\"Processing queries\"):\n",
        "            original_ranking = self.data[\"pre_ranking\"][query_id]\n",
        "\n",
        "            # Ensure we work with exactly 30 documents\n",
        "            working_docs = original_ranking[:30]\n",
        "\n",
        "            # Re-rank\n",
        "            reranked = self._rerank_documents(query_id, working_docs)\n",
        "\n",
        "            # Preserve all original documents\n",
        "            predictions[query_id] = [did for did in reranked if did in original_ranking]\n",
        "            predictions[query_id].extend(did for did in original_ranking if did not in predictions[query_id])\n",
        "\n",
        "            # Validation\n",
        "            assert len(predictions[query_id]) == len(original_ranking)\n",
        "            assert set(predictions[query_id]) == set(original_ranking)\n",
        "\n",
        "        # Save with exact required format\n",
        "        with open(self.config[\"output_file\"], \"w\") as f:\n",
        "            json.dump(predictions, f)\n",
        "\n",
        "        print(f\"Submission file generated: {self.config['output_file']}\")\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "7LQl7NsGe1Te"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = PatentReranker(CONFIG)"
      ],
      "metadata": {
        "id": "ALGaWLDMfEEc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = reranker.generate_submission()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyjSEwlNdroH",
        "outputId": "bef01da8-c879-49d7-fb88-c2ce83d86b61"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:35<00:00,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file generated: prediction2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDsubAeqds87"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f805439dcde457296ca7b45823abbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f1a4118201842a39089e3637d81156e",
              "IPY_MODEL_5a621d0449ce49bc8220944d8eddb228",
              "IPY_MODEL_2c3b83e9e45e4cbca3540cad62195138"
            ],
            "layout": "IPY_MODEL_9b94c57e3fd94fba91817764faeb1b98"
          }
        },
        "5f1a4118201842a39089e3637d81156e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593ecc7c30a14af19f2191d4b8fc0390",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9be351be88634168900c10dcc0b818e3",
            "value": "Batches:â€‡100%"
          }
        },
        "5a621d0449ce49bc8220944d8eddb228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecbd2256d3bb4ac4bff77361d06af675",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9c9220cba2248e2bbdea32c33226b20",
            "value": 29
          }
        },
        "2c3b83e9e45e4cbca3540cad62195138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58e47e447b84c86aece5e74ec6cc6cd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3446f7f9db7042e3a5cdb5b9edb177bd",
            "value": "â€‡29/29â€‡[00:37&lt;00:00,â€‡â€‡1.26it/s]"
          }
        },
        "9b94c57e3fd94fba91817764faeb1b98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593ecc7c30a14af19f2191d4b8fc0390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be351be88634168900c10dcc0b818e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecbd2256d3bb4ac4bff77361d06af675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9c9220cba2248e2bbdea32c33226b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d58e47e447b84c86aece5e74ec6cc6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3446f7f9db7042e3a5cdb5b9edb177bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1894c4d5f05a4fde932f06c2b386a213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d4f8d1d39004dc1a17a7c7d6b0c4285",
              "IPY_MODEL_13be0f874076458d878553637d26ed22",
              "IPY_MODEL_2bfe19e92e164875a636b7e75ca88e75"
            ],
            "layout": "IPY_MODEL_83d0b8971755412fbc2916236fe8c748"
          }
        },
        "3d4f8d1d39004dc1a17a7c7d6b0c4285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e7ef78ea25463d8a04f2dbc3534a16",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8eebcb0373ef4be59508284e1f908843",
            "value": "Batches:â€‡100%"
          }
        },
        "13be0f874076458d878553637d26ed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0813ca2d96e34625854cb3150db78f44",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb27edf825a04b9f82f803950f861c7b",
            "value": 29
          }
        },
        "2bfe19e92e164875a636b7e75ca88e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7705ae862c04aadb12340ce2e99dceb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b0e4c9629d24a1a88c1f8e2d046a832",
            "value": "â€‡29/29â€‡[01:17&lt;00:00,â€‡â€‡1.48s/it]"
          }
        },
        "83d0b8971755412fbc2916236fe8c748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e7ef78ea25463d8a04f2dbc3534a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eebcb0373ef4be59508284e1f908843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0813ca2d96e34625854cb3150db78f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb27edf825a04b9f82f803950f861c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7705ae862c04aadb12340ce2e99dceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0e4c9629d24a1a88c1f8e2d046a832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36241357cfb4e71830c67b3a6dc3cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2762b0401e8f46aea987504fb4622bc1",
              "IPY_MODEL_f6afdaf8acd64b698197fa2e648150ee",
              "IPY_MODEL_eddb16de9dd6477b981f21a924104037"
            ],
            "layout": "IPY_MODEL_d79d8fe993e7479380c532e67553335e"
          }
        },
        "2762b0401e8f46aea987504fb4622bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4315521d259c4501be6db90ff5b5aad9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9bb567f8df44db89dd2ffae6318676c",
            "value": "Batches:â€‡100%"
          }
        },
        "f6afdaf8acd64b698197fa2e648150ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fab72471ef148b8954fae0058eda580",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27f0ee3a5dda44379004fb145582a6d7",
            "value": 29
          }
        },
        "eddb16de9dd6477b981f21a924104037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd149bff6f44a8796c93cc49a2eaa0f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a48fe086795d4413866b46d8f107c220",
            "value": "â€‡29/29â€‡[01:18&lt;00:00,â€‡â€‡1.48s/it]"
          }
        },
        "d79d8fe993e7479380c532e67553335e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4315521d259c4501be6db90ff5b5aad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bb567f8df44db89dd2ffae6318676c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fab72471ef148b8954fae0058eda580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f0ee3a5dda44379004fb145582a6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fd149bff6f44a8796c93cc49a2eaa0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48fe086795d4413866b46d8f107c220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "963c0a96dd534ce997649bf332438d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acde63c4177b48229bb8a2fc479f1642",
              "IPY_MODEL_b9c237694adc49aea6db79ca4a98a9e2",
              "IPY_MODEL_623060236bcd4e0ea9ee53885345dcc2"
            ],
            "layout": "IPY_MODEL_1834d4421a80441daf4782da40720a4e"
          }
        },
        "acde63c4177b48229bb8a2fc479f1642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d59320f3a24e76bd9b69c3bf7417d5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_231e4dfab2f2466d928b73b1c9f36ed0",
            "value": "Batches:â€‡100%"
          }
        },
        "b9c237694adc49aea6db79ca4a98a9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ec38d86e8a4ec9ae6a36fb40e02780",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88d8dfaf29d54da992b6e6624ef48b18",
            "value": 29
          }
        },
        "623060236bcd4e0ea9ee53885345dcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0910e1120e6f410bb0bfb67cb4487d33",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6dc2cc5f97c7415a9ab7b9079a37316f",
            "value": "â€‡29/29â€‡[01:28&lt;00:00,â€‡â€‡2.22s/it]"
          }
        },
        "1834d4421a80441daf4782da40720a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d59320f3a24e76bd9b69c3bf7417d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231e4dfab2f2466d928b73b1c9f36ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2ec38d86e8a4ec9ae6a36fb40e02780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d8dfaf29d54da992b6e6624ef48b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0910e1120e6f410bb0bfb67cb4487d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc2cc5f97c7415a9ab7b9079a37316f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468e881ed4a5401b921f026bf50f9fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a1858b2f35a4310a9d1d49f8b4de813",
              "IPY_MODEL_04b3db8f14cc45108d1abfbc58295c99",
              "IPY_MODEL_98c2e6d76d174fa0b0bec6d0cfc21903"
            ],
            "layout": "IPY_MODEL_67bf5f2164064a6ea8da1e6d9a74e3f4"
          }
        },
        "1a1858b2f35a4310a9d1d49f8b4de813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4e46f1876a46cca23ae3cf0fef08a4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e2a8d831fc2b47ecad2f4d25952a843b",
            "value": "Batches:â€‡100%"
          }
        },
        "04b3db8f14cc45108d1abfbc58295c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306d6a50ff274c2b9290721b5d20777e",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_984a37e6d9594941b3046dcd8424dce2",
            "value": 29
          }
        },
        "98c2e6d76d174fa0b0bec6d0cfc21903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1626754fa74f71ad06921690efced6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_535afa9acf334e398d03a4a237b434e5",
            "value": "â€‡29/29â€‡[00:00&lt;00:00,â€‡45.17it/s]"
          }
        },
        "67bf5f2164064a6ea8da1e6d9a74e3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4e46f1876a46cca23ae3cf0fef08a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a8d831fc2b47ecad2f4d25952a843b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306d6a50ff274c2b9290721b5d20777e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984a37e6d9594941b3046dcd8424dce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a1626754fa74f71ad06921690efced6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535afa9acf334e398d03a4a237b434e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}